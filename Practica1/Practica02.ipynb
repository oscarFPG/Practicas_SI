{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ccf9884",
   "metadata": {},
   "source": [
    "# Preparación de datos con Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f442b51",
   "metadata": {},
   "source": [
    "Autores: Ismael Sagredo Olivenza y Fernando Carlos López Hernández"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11703f9",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c297625",
   "metadata": {},
   "source": [
    "Pandas es el acrónimo de (Python Data Analysis Library) es un código fuente open source con licencia BSD que proporciona estructuras de datos, herramientas de análisis en python, fáciles de usar y de alto rendimiento.\n",
    "\n",
    "**Dataframe**\n",
    "\n",
    "Es la estuctura fundamental de Pandas. Es una especie de tabla que permite cargar información proveniente de un fichero y poder manejarla a nuestro antojo. Soporta importación directa desde csv lo que es muy útil ya que es el formato más extendido de los diferentes datasets que están publicados en internet.\n",
    "El dataframe puede tener en cada columna un tipo de datos diferentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94476dc",
   "metadata": {},
   "source": [
    "Vamos a trabajar con Python para tener cierta soltura con el lenguaje antes realizar los laboratorios.\n",
    "Para ello vamos a realizar el siguiente ejercicios que consisten en trabajar con el datase de películas de movielens dataset que se puede descargar aquí:\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "Lo primero que haremos será cargar el fichero movies_metadata.csv usando Pandas en un dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ded621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "movies = pd.read_csv('movies_metadata.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce1e65a",
   "metadata": {},
   "source": [
    "El warning se produce porque hay algunos campos del dataset que son multicampo y no sabe de que tipo son. Vamos a establecer los tipos para que desaparezca el warning. Como nos indica que el campo que no conoce es el 10, establecemos el 10 como str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies = pd.read_csv('movies_metadata.csv',dtype={ 10 : 'str'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f1fd97",
   "metadata": {},
   "source": [
    "Podemos visualizar el dataframe entero usando display. Pero en muchas ocasiones nos interesa mostrar solo una parte del dataframe para que podamos ver que pinta tiene el dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6b5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movies.head(n=4));\n",
    "display(movies.tail(n=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e36b9e",
   "metadata": {},
   "source": [
    "Echamos un vistazo al dataframe, los principales campos que nos interesan son el id, el original_title, los géneros, pero también hay otros interesantes como el rating medio vote_ average.\n",
    "\n",
    "Ahora cargamos el fichero de ratings ratings_small.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20395893",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac1141",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ratings.head(n=4));\n",
    "display(ratings.tail(n=4));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc5d51d",
   "metadata": {},
   "source": [
    "En el fichero rating tenemos las valoraciones de los usuarios identificados con un id anónimo (userId) y el identificador de la palícula (movieId). De esta forma podemos relacionar ambos dataframes. Por ejemplo, si queremos buscar todas las votaciones de una película concreta podemos extraer el id de la película que queremos buscar y con ese id consultar los ratings. Buscamos por ejemplo la película \"The Lation King\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ad28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lion = movies[movies[\"title\"] == \"The Lion King\"]\n",
    "display(lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ccb02f",
   "metadata": {},
   "source": [
    "Pero buscar en un campo de texto de esta forma es complicado, ya que podemos estar buscando un texto y este no estar escrito exactamente igual que el almacenado (puedes poner una letra minúscula en alguna de las mayúsculas para comprobarlo). Una solución es buscar parcialmente. Pandas no lo permite hacer directamente, pero tenemos algunos trucos para conseguirlo, por ejemplo usando máscaras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2849d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = 'lion king'\n",
    "#Hacemos una subselección de los dos campos que nos interesan y los copiamos a otro dataframe\n",
    "titles=movies[[\"original_title\",\"id\"]].copy();\n",
    "# Nos creamos una máscara con el método applymap que nos indica que campos contienen una condición que establecemos mediante una lambda\n",
    "mask = titles.applymap(lambda x:  tested.lower() in str(x).lower())\n",
    "# Aplicamos la mascara para encontrar que campos nos interesan usando la función any\n",
    "df1 = titles[mask.any(axis=1)]\n",
    "#Any nos devuelve la fila o columna (dependiendo del axis) que al menos tenga un campo a true de la máscara. Axis 1 indica\n",
    "# la columna en este caso. Si queremos devolver la fila, sería axis = 0\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d1fe0",
   "metadata": {},
   "source": [
    "Nos encuentra tres de las películas de de la saga de The Lion King. Ahora podemos identificar correctamente el criterio de búisqueda para seleccionar correctamente el que deseamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9043db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lion = movies[movies[\"title\"] == \"The Lion King\"]\n",
    "display(lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f1a5df",
   "metadata": {},
   "source": [
    "Identificada la entrada de la película que queremos buscar, ahora procedemos, usando el ID a buscar los ratings de dicha película. Para acceder al valor del id tenemos que usar la función loc que define una selección a traves de un indice, en nuestro caso el 0 que nos devolverá la fila del índice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lionId = int(lion[\"id\"].loc[lion.index[0]])\n",
    "#lionId = movies[movies[\"title\"] == \"The Lion King\"][\"id\"]\n",
    "print(lionId)\n",
    "ratingLion = ratings[ratings[\"movieId\"] == lionId]\n",
    "display(ratingLion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c8acec",
   "metadata": {},
   "source": [
    "Ahora queremos calcular la media de las valoraciones de la película en el fichero de ratings. Para ello vamos a ejecutar la función mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7de23f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratingLion[\"rating\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d0fba",
   "metadata": {},
   "source": [
    "Entre los campos vemos que hay un timestamp, vamos a convertirlo a date y le cambiamos el nombre a la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfeb4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "ratings[\"timestamp\"] = ratings[\"timestamp\"].apply(lambda x:  datetime.datetime.fromtimestamp(x).isoformat())\n",
    "ratings.rename(columns = {'timestamp':'datetime'}, inplace = True)\n",
    "display(ratings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8d8514",
   "metadata": {},
   "source": [
    "vamos a extraer el género de la película, lo primero que vemos es que los nombres estan con comillas simples, esto provoca un error en el parseo de json, asi que debemos primero limpiar la info usando replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = lion[\"genres\"].loc[lion.index[0]];\n",
    "genre = genre.replace(\"'\", \"\\\"\")\n",
    "import json\n",
    "genreArray = json.loads(genre)\n",
    "for g in genreArray:\n",
    "    print(g[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8a060",
   "metadata": {},
   "source": [
    "Ahora vamos a aplicar una función que convierta los géneros en una cadena separada por comas para poder usarla en nuestras consultas más cómodamente. Para ello vamos a usar la función apply que nos permite aplicar una función a una fila o columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8066f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_genre(x):\n",
    "    x = x.replace(\"'\", \"\\\"\")\n",
    "    xArr = json.loads(x)\n",
    "    strOut = \"\"\n",
    "    for g in xArr:\n",
    "        strOut = strOut + g[\"name\"] + \",\"\n",
    "    strOut = strOut[0:-1]\n",
    "    return strOut\n",
    "\n",
    "\n",
    "movies[\"genres\"] = movies[\"genres\"].apply(transform_genre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da47f6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b13a9a2",
   "metadata": {},
   "source": [
    "Ahora podemos buscar todas las películas de animación y por ejemplo calcular su puntuación media usando una máscara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e4a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "tested = \"Animation\"\n",
    "maskGenre = movies.applymap(lambda x:  tested.lower() in str(x).lower())\n",
    "animation = movies[maskGenre.any(axis=1)]\n",
    "display(animation.head())\n",
    "print(animation[\"vote_average\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc895ab9",
   "metadata": {},
   "source": [
    "Ahora vamos a contar aquellas películas que tenían video y ver si son más que las que no lo tienen, para ello usamos groupby. Esta función agrupa por uno o varios campos, haciendo una especie de lista de colisiones para el resto de campos, de forma que podemos luego hacer preguntas sobre la lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7dfac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numVideo = movies.groupby(\"video\").count()\n",
    "display(numVideo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b87a",
   "metadata": {},
   "source": [
    "Como vemos, la función count se aplica a todos los campos de la lista de colisión. Pero podemos aplicarlo a un campo concreto, al que nos interese, para que sea más óptimo. Por ejemplo vamos a calcular el runtime medio de las películas de video y las que no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96541f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenueVideo = movies.groupby(\"video\")[\"runtime\"].mean()\n",
    "print(revenueVideo[revenueVideo.index[0]])\n",
    "print(revenueVideo[revenueVideo.index[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbcde05",
   "metadata": {},
   "source": [
    "Cargamos el fichero credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7487bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "credits = pd.read_csv('credits.csv')\n",
    "display(credits.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe2c65",
   "metadata": {},
   "source": [
    "Y hacemos un merge entre movies y credits por el campo id. Si el campo id es int64 convertirlo a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f851b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies[\"id\"] = movies[\"id\"].astype(str)\n",
    "credits[\"id\"] = credits[\"id\"].astype(str)\n",
    "movie_credits = pd.merge(movies,credits,how='inner',on=('id'))\n",
    "display(movie_credits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fab295",
   "metadata": {},
   "source": [
    "Ahora podemos saber los actores de una película, pero tambien que películas ha hecho un actor.\n",
    "## Ejercicio 01\n",
    "Buscar todas las películas interpretadas por **Bruce Willis**. Pero nos vamos a encontrar nuevamente con problemas en el json. Hay dos estrategias posibles, limpiar el json o ir al grano. Limpiar el json será costoso y dará bastantes problemas os proponemos la segunda opción:\n",
    "Hay que crear una función que convierta Json a array por espacios. La función anterior no nos vale porque este json tiene errores que hay que subsanar más allá de convertir comillas simples por dobles (por ejemplo algunos campos tiene comillas simples en el interior del campo), por lo que es mejor ir directamente a procesar los campos name: <nombre del actor> extraerlos y contruir una lista sin usar el parser de json.\n",
    "    \n",
    "NOTA: Esto es muy típico en los datasets, no todos los datos vienen limpios y gran parte del trabajo en IA en general y Machine Learning en particular es preprocesar los datos paraque nos sean útiles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aqui el ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccf2ce3",
   "metadata": {},
   "source": [
    "Vamos a filtrar todas las películas de animación que tienen homepage y vamos a crearnos un dataframe manualmente con tres columnas, el id de la película, el título y el homepage y generaremos un número aleatorio . Después, escribiremos el dataframe como csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7be4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimationHomepage = animation[animation[\"homepage\"].notnull()]\n",
    "display(AnimationHomepage)\n",
    "NewAnimationHomepage = pd.DataFrame({'id':AnimationHomepage['id'],\n",
    "                          'homepage':AnimationHomepage[\"homepage\"],\n",
    "                          'title':AnimationHomepage[\"title\"]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f68d3a",
   "metadata": {},
   "source": [
    "Escribimos el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8609fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewAnimationHomepage.to_csv(\"NewAnimationHomepage.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ec95a9",
   "metadata": {},
   "source": [
    "## Uso de sklearn para calcular una regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f3b827",
   "metadata": {},
   "source": [
    "Sklearn es la libreria principal que vamos a utilizar para aplicar técnicas\n",
    "de aprendizaje máquina. Pero despone de multitud de herramientas que son útiles\n",
    "Por ejemplo dispone de regresión lineal.\n",
    "\n",
    "Vamos a optener la ecuación lineal que minimiza el error cuadrático medio.\n",
    "Esta ecuación constará de una variable dependiente y un conjunto de variables\n",
    "independientes.\n",
    "\n",
    "Para cada x se optendrá un error concreto en función de la distancia existente\n",
    "entre el punto marcado por la recta y el valor real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a471e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "#cargando el dataset de diabetes que incorpora sklearn.\n",
    "diabetes = datasets.load_diabetes()\n",
    "#usamos solo una caracteristica\n",
    "diabetes_x = diabetes.data[:,np.newaxis,2]\n",
    "#dividimos el dato ente entrenamiento y validación o test.\n",
    "#esto es algo recurrente cuando hacemos aprendizaje máquina.\n",
    "\n",
    "diabetes_x_train = diabetes_x[:-20] # Todos menos los 20 ultimos.\n",
    "\n",
    "diabetes_x_test = diabetes_x[-20:] # desde el puesto 10 empezanod por le final hasta el final\n",
    "\n",
    "# luego cogemos las clases para obtener los valores esperados.\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "\n",
    "#creamos la regresión lineal:\n",
    "linearreg = linear_model.LinearRegression()\n",
    "linearreg.fit(diabetes_x_train, diabetes_y_train)\n",
    "\n",
    "#Comprobamos la capacidad de predicción\n",
    "diabetes_y_pred = linearreg.predict(diabetes_x_test)\n",
    "print(\"Mostramos los valores obtenidos por la regresión lineal\")\n",
    "print('Coeficientes: \\n', linearreg.coef_)\n",
    "print(\"MSE: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "print('R2: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred)) #coeficiente de regresión.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cb5a3",
   "metadata": {},
   "source": [
    "Ahora dibujamos una gráfica usando matplotlib.pyplot que muestre la matriz de puntos y al recta de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b63df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(diabetes_x_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_x_test, diabetes_y_pred, color='blue', linewidth=3) #en linewidth le indicamos la linea en la gráfica.\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b197f7",
   "metadata": {},
   "source": [
    "# Ejercicio 02\n",
    "Realiza otra recta de regresión del dataset \"Boston\" (Boston house prices) que tambien podeis encontrar en sklearn, pintando su gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f8a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aqui el ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed114b16",
   "metadata": {},
   "source": [
    "# Ejercicio 03\n",
    "Basándote en datos aleatorios (los que quieras) crea un gráfico de tarta (pie chart) con Mapplotlib. La gráfica debe tener un título, etiquetas de cada clase, visible los porcentajes de cada clase y opcionalmente una de las clases resaltadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9434135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribe aqui el ejercicio 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
